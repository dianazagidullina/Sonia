{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile\n",
    "from mido import Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_midi(count):\n",
    "    list_mid = []\n",
    "    for i in range(1, count + 1):\n",
    "        path = '/Users/diana/Documents/Project/train_songs_3/' + str(i) + '.MID'\n",
    "        list_mid.append(MidiFile(path))\n",
    "    return list_mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_midi(mid, dur):\n",
    "    note = []\n",
    "    msg_type = []\n",
    "    time = []\n",
    "    time_now = 0\n",
    "    for msg in mid.play():\n",
    "        time_now += msg.time\n",
    "        if (time_now > dur):\n",
    "            return note, msg_type, time\n",
    "        if (msg.type == 'note_on' or msg.type == 'note_off'):\n",
    "            msg_type.append(msg.type)\n",
    "            note.append(msg.note)\n",
    "            time.append(time_now)\n",
    "    print(time_now)\n",
    "    return note, msg_type, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_data(note, msg_type, time, sz):\n",
    "    note = note[:sz]\n",
    "    msg_type = msg_type[:sz]\n",
    "    time = time[:sz]\n",
    "    return note, msg_type, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_dur(time, max_dur_note, amount_dur):\n",
    "    for i in range(amount_dur):\n",
    "        if (max_dur_note / amount_dur * i < time and max_dur_note / amount_dur * (i + 1) >= time):\n",
    "            return i\n",
    "    return amount_dur - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexes_from_midi(note, msg_type, time, max_dur_note, amount_dur, each_dur):\n",
    "    indexes = []\n",
    "    time_last = 0\n",
    "    empty = 128 * amount_dur\n",
    "    sz = len(note)\n",
    "    \n",
    "    for i in range(sz):\n",
    "        if (msg_type[i] == 'note_on'):\n",
    "            j = i + 1\n",
    "            while (j < sz and note[i] != note[j]):\n",
    "                j += 1\n",
    "            if (j >= sz):\n",
    "                t_dur = type_dur(max_dur_note, max_dur_note, amount_dur)\n",
    "            else:\n",
    "                t_dur = type_dur(time[j] - time[i], max_dur_note, amount_dur)\n",
    "                print(t_dur)\n",
    "            while (time_last + each_dur < time[i]):\n",
    "                indexes.append(empty)\n",
    "                time_last += each_dur\n",
    "            indexes.append(note[i] + 128 * t_dur)\n",
    "    indexes.append(EOS_token)\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import Message, MidiFile, MidiTrack\n",
    "from operator import itemgetter\n",
    "def midi_from_indexes(indexes, max_dur_note, amount_dur, each_dur):\n",
    "    time_now = 0\n",
    "    events = []\n",
    "    for i in range(len(indexes)):\n",
    "        if (indexes[i] == '<EOS>'):\n",
    "            note = -1\n",
    "        elif (indexes[i] == 128 * amount_dur):\n",
    "            note = -1\n",
    "        else:\n",
    "            note = indexes[i] % 128\n",
    "            \n",
    "            type_dur = (indexes[i] - note) / 128\n",
    "            print(type_dur)\n",
    "            dur = max_dur_note / amount_dur * (type_dur + 1)\n",
    "        if (note != -1):\n",
    "            events.append([time_now, 'note_on', note])\n",
    "            events.append([time_now + dur, 'note_off', note])\n",
    "        time_now += each_dur\n",
    "    events = sorted(events,key=itemgetter(0))\n",
    "    for i in range(len(events) - 1, 0, -1):\n",
    "        events[i][0] -= events[i - 1][0]\n",
    "    mid = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    mid.tracks.append(track)\n",
    "    for ev in events:\n",
    "        track.append(Message(ev[1], note=ev[2], velocity=64, time=int(ev[0]/0.0013354687499999999)))\n",
    "    return mid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_data(dur, count):\n",
    "    list_mid = download_midi(count)\n",
    "    data = []\n",
    "    for i in range(count):\n",
    "        print(list_mid[i])\n",
    "        note, msg_type, time = get_data_from_midi(list_mid[i], dur)\n",
    "        data.append([note, msg_type, time])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dur_note = 4\n",
    "amount_dur = 10\n",
    "each_dur = 0.2\n",
    "hidden_size = 256\n",
    "list_indexes = []\n",
    "duration = 60\n",
    "count = 16\n",
    "SOS_token = 128 * amount_dur + 1\n",
    "EOS_token = 128 * amount_dur + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<midi file '/Users/diana/Documents/Project/train_songs_3/1.MID' type 0, 1 tracks, 5632 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/2.MID' type 0, 1 tracks, 8575 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/3.MID' type 0, 1 tracks, 11928 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/4.MID' type 0, 1 tracks, 15227 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/5.MID' type 0, 1 tracks, 19976 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/6.MID' type 0, 1 tracks, 20010 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/7.MID' type 0, 1 tracks, 24237 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/8.MID' type 0, 1 tracks, 24842 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/9.MID' type 0, 1 tracks, 25946 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/10.MID' type 0, 1 tracks, 34908 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/11.MID' type 1, 2 tracks, 275 messages>\n",
      "53.93906250000014\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/12.MID' type 1, 2 tracks, 276 messages>\n",
      "23.451171875\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/13.MID' type 1, 2 tracks, 851 messages>\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/14.MID' type 1, 2 tracks, 222 messages>\n",
      "54.85708800000009\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/15.MID' type 1, 2 tracks, 233 messages>\n",
      "17.0\n",
      "<midi file '/Users/diana/Documents/Project/train_songs_3/16.MID' type 1, 2 tracks, 398 messages>\n"
     ]
    }
   ],
   "source": [
    "data = get_list_data(duration, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-41a90b60928a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mEOS_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mamount_dur\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlist_indexes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexes_from_midi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dur_note\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamount_dur\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meach_dur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(count):\n",
    "    list_indexes.append(indexes_from_midi(data[i][0], data[i][1], data[i][2], max_dur_note, amount_dur, each_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import timeit\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MAX_LENGTH = 100000000\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 1\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, decoder, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = input_tensor\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(count, target_indexes, decoder, print_every=2, plot_every=100, learning_rate=0.000001, n_iters = 100, rand = 30):\n",
    "    start = time.time()\n",
    "    \n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    #decoder_optimizer = optim.RMSprop(decoder.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False)\n",
    "    #encoder_optimizer = torch.optim.ASGD(encoder.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "    #decoder_optimizer = torch.optim.ASGD(decoder.parameters(), lr=0.01, lambd=0.0001, alpha=0.75, t0=1000000.0, weight_decay=0)\n",
    "    \n",
    "     \n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        input_rand = []\n",
    "        a = random.randint(1, rand)\n",
    "        for i in range(0, hidden_size):\n",
    "            input_rand.append(a)\n",
    "        input_rand = np.reshape(input_rand, (1, 1, hidden_size))\n",
    "        \n",
    "        input_tensor = torch.FloatTensor(input_rand)\n",
    "        t = target_indexes[iter%count]\n",
    "        target_tensor = torch.tensor(t, dtype=torch.long, device=device).view(-1, 1)\n",
    "        loss = train(input_tensor, target_tensor, \n",
    "                     decoder, decoder_optimizer, criterion)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_rand, decoder, max_length=MAX_LENGTH, most_prob = 5):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        \n",
    "        input_tensor = torch.FloatTensor(input_rand)\n",
    "        decoder_hidden = input_tensor\n",
    "        \n",
    "        decoded_words = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(most_prob)\n",
    "            i = random.randint(0, most_prob - 1)\n",
    "            \n",
    "            topv = topv[0][i]\n",
    "            topi = topi[0][i]\n",
    "\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(topi.item())\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "decoder = DecoderRNN(hidden_size, 128 * amount_dur + 3).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0m 4s (- 12m 53s) (3 0%) 3.9383\n",
      "0m 6s (- 9m 23s) (6 1%) 2.9825\n",
      "0m 11s (- 10m 11s) (9 1%) 4.1634\n",
      "0m 12s (- 8m 47s) (12 2%) 3.3511\n",
      "0m 14s (- 7m 53s) (15 3%) 3.0942\n",
      "0m 19s (- 8m 35s) (18 3%) 4.0531\n",
      "0m 22s (- 8m 22s) (21 4%) 3.0392\n",
      "0m 26s (- 8m 40s) (24 4%) 3.8413\n",
      "0m 29s (- 8m 32s) (27 5%) 4.1267\n",
      "0m 30s (- 7m 59s) (30 6%) 3.0516\n",
      "0m 33s (- 7m 52s) (33 6%) 3.3249\n",
      "0m 37s (- 8m 0s) (36 7%) 3.7215\n",
      "0m 40s (- 7m 56s) (39 7%) 3.4878\n",
      "0m 43s (- 7m 54s) (42 8%) 3.6302\n",
      "0m 45s (- 7m 38s) (45 9%) 3.4217\n",
      "0m 47s (- 7m 31s) (48 9%) 3.5790\n",
      "0m 51s (- 7m 37s) (51 10%) 3.9307\n",
      "0m 54s (- 7m 30s) (54 10%) 2.9820\n",
      "0m 58s (- 7m 34s) (57 11%) 4.1488\n",
      "1m 0s (- 7m 21s) (60 12%) 3.3053\n",
      "1m 1s (- 7m 8s) (63 12%) 3.0280\n",
      "1m 6s (- 7m 14s) (66 13%) 4.0516\n",
      "1m 8s (- 7m 7s) (69 13%) 3.0441\n",
      "1m 11s (- 7m 5s) (72 14%) 3.8608\n",
      "1m 14s (- 7m 3s) (75 15%) 4.1056\n",
      "1m 16s (- 6m 52s) (78 15%) 3.0928\n",
      "1m 19s (- 6m 49s) (81 16%) 3.3240\n",
      "1m 22s (- 6m 49s) (84 16%) 3.7082\n",
      "1m 25s (- 6m 45s) (87 17%) 3.4995\n",
      "1m 28s (- 6m 43s) (90 18%) 3.5984\n",
      "1m 30s (- 6m 34s) (93 18%) 3.4498\n",
      "1m 32s (- 6m 28s) (96 19%) 3.5025\n",
      "1m 36s (- 6m 29s) (99 19%) 3.9286\n",
      "1m 38s (- 6m 23s) (102 20%) 3.0012\n",
      "1m 42s (- 6m 24s) (105 21%) 4.1433\n",
      "1m 43s (- 6m 16s) (108 21%) 3.2729\n",
      "1m 45s (- 6m 8s) (111 22%) 3.0395\n",
      "1m 49s (- 6m 10s) (114 22%) 4.0420\n",
      "1m 51s (- 6m 5s) (117 23%) 3.0368\n",
      "1m 54s (- 6m 3s) (120 24%) 3.8505\n",
      "1m 57s (- 6m 0s) (123 24%) 4.1105\n",
      "1m 58s (- 5m 52s) (126 25%) 3.0896\n",
      "2m 1s (- 5m 50s) (129 25%) 3.3343\n",
      "2m 5s (- 5m 50s) (132 26%) 3.7008\n",
      "2m 8s (- 5m 48s) (135 27%) 3.4803\n",
      "2m 12s (- 5m 46s) (138 27%) 3.5913\n",
      "2m 13s (- 5m 40s) (141 28%) 3.3764\n",
      "2m 17s (- 5m 39s) (144 28%) 3.5697\n",
      "2m 21s (- 5m 40s) (147 29%) 3.9272\n",
      "2m 23s (- 5m 35s) (150 30%) 2.9893\n",
      "2m 27s (- 5m 34s) (153 30%) 4.1405\n",
      "2m 29s (- 5m 29s) (156 31%) 3.2840\n",
      "2m 30s (- 5m 23s) (159 31%) 3.1033\n",
      "2m 35s (- 5m 24s) (162 32%) 4.0382\n",
      "2m 37s (- 5m 20s) (165 33%) 3.0332\n",
      "2m 41s (- 5m 18s) (168 33%) 3.8544\n",
      "2m 44s (- 5m 15s) (171 34%) 4.1217\n",
      "2m 45s (- 5m 9s) (174 34%) 3.1662\n",
      "2m 48s (- 5m 7s) (177 35%) 3.3361\n",
      "2m 52s (- 5m 6s) (180 36%) 3.6997\n",
      "2m 55s (- 5m 3s) (183 36%) 3.4757\n",
      "2m 58s (- 5m 0s) (186 37%) 3.6116\n",
      "2m 59s (- 4m 55s) (189 37%) 3.3497\n",
      "3m 1s (- 4m 51s) (192 38%) 3.5624\n",
      "3m 5s (- 4m 50s) (195 39%) 3.9199\n",
      "3m 9s (- 4m 48s) (198 39%) 2.9752\n",
      "3m 13s (- 4m 47s) (201 40%) 4.1476\n",
      "3m 15s (- 4m 43s) (204 40%) 3.2931\n",
      "3m 16s (- 4m 37s) (207 41%) 3.0840\n",
      "3m 20s (- 4m 36s) (210 42%) 4.0384\n",
      "3m 22s (- 4m 32s) (213 42%) 3.0527\n",
      "3m 25s (- 4m 30s) (216 43%) 3.8481\n",
      "3m 28s (- 4m 27s) (219 43%) 4.0919\n",
      "3m 29s (- 4m 22s) (222 44%) 3.1494\n",
      "3m 32s (- 4m 19s) (225 45%) 3.3114\n",
      "3m 36s (- 4m 18s) (228 45%) 3.7033\n",
      "3m 39s (- 4m 15s) (231 46%) 3.4640\n",
      "3m 42s (- 4m 13s) (234 46%) 3.5895\n",
      "3m 44s (- 4m 9s) (237 47%) 3.3713\n",
      "3m 46s (- 4m 5s) (240 48%) 3.4580\n",
      "3m 50s (- 4m 3s) (243 48%) 3.9127\n",
      "3m 52s (- 4m 0s) (246 49%) 2.9902\n",
      "3m 56s (- 3m 58s) (249 49%) 4.1474\n",
      "3m 58s (- 3m 54s) (252 50%) 3.2713\n",
      "3m 59s (- 3m 50s) (255 51%) 3.0271\n",
      "4m 3s (- 3m 48s) (258 51%) 4.0284\n",
      "4m 6s (- 3m 45s) (261 52%) 3.0307\n",
      "4m 9s (- 3m 43s) (264 52%) 3.8246\n",
      "4m 13s (- 3m 40s) (267 53%) 4.0617\n",
      "4m 14s (- 3m 36s) (270 54%) 3.0680\n",
      "4m 17s (- 3m 33s) (273 54%) 3.2972\n",
      "4m 20s (- 3m 31s) (276 55%) 3.6908\n",
      "4m 23s (- 3m 28s) (279 55%) 3.4820\n",
      "4m 27s (- 3m 26s) (282 56%) 3.5998\n",
      "4m 28s (- 3m 22s) (285 56%) 3.3491\n",
      "4m 31s (- 3m 19s) (288 57%) 3.4708\n",
      "4m 35s (- 3m 17s) (291 58%) 3.9092\n",
      "4m 37s (- 3m 14s) (294 58%) 3.0006\n",
      "4m 41s (- 3m 12s) (297 59%) 4.1189\n",
      "4m 43s (- 3m 9s) (300 60%) 3.2806\n",
      "4m 45s (- 3m 5s) (303 60%) 3.0755\n",
      "4m 49s (- 3m 3s) (306 61%) 4.0305\n",
      "4m 52s (- 3m 0s) (309 61%) 3.0264\n",
      "4m 55s (- 2m 57s) (312 62%) 3.8493\n",
      "4m 58s (- 2m 55s) (315 63%) 4.0683\n",
      "4m 59s (- 2m 51s) (318 63%) 3.0452\n",
      "5m 2s (- 2m 48s) (321 64%) 3.2962\n",
      "5m 6s (- 2m 46s) (324 64%) 3.6843\n",
      "5m 9s (- 2m 43s) (327 65%) 3.4742\n",
      "5m 12s (- 2m 41s) (330 66%) 3.5859\n",
      "5m 14s (- 2m 37s) (333 66%) 3.4461\n",
      "5m 17s (- 2m 34s) (336 67%) 3.5022\n",
      "5m 21s (- 2m 32s) (339 67%) 3.9037\n",
      "5m 23s (- 2m 29s) (342 68%) 2.9935\n",
      "5m 27s (- 2m 27s) (345 69%) 4.1408\n",
      "5m 29s (- 2m 23s) (348 69%) 3.2972\n",
      "5m 31s (- 2m 20s) (351 70%) 3.0358\n",
      "5m 35s (- 2m 18s) (354 70%) 4.0255\n",
      "5m 38s (- 2m 15s) (357 71%) 3.0303\n",
      "5m 41s (- 2m 12s) (360 72%) 3.8146\n",
      "5m 44s (- 2m 10s) (363 72%) 4.0949\n",
      "5m 46s (- 2m 6s) (366 73%) 3.0947\n",
      "5m 49s (- 2m 4s) (369 73%) 3.2966\n",
      "5m 53s (- 2m 1s) (372 74%) 3.6790\n",
      "5m 56s (- 1m 58s) (375 75%) 3.4688\n",
      "5m 59s (- 1m 56s) (378 75%) 3.5582\n",
      "6m 1s (- 1m 52s) (381 76%) 3.4329\n",
      "6m 3s (- 1m 49s) (384 76%) 3.5068\n",
      "6m 7s (- 1m 47s) (387 77%) 3.8950\n",
      "6m 9s (- 1m 44s) (390 78%) 2.9861\n",
      "6m 13s (- 1m 41s) (393 78%) 4.1139\n",
      "6m 15s (- 1m 38s) (396 79%) 3.3028\n",
      "6m 16s (- 1m 35s) (399 79%) 3.0069\n",
      "6m 21s (- 1m 32s) (402 80%) 4.0107\n",
      "6m 23s (- 1m 29s) (405 81%) 3.0199\n",
      "6m 26s (- 1m 27s) (408 81%) 3.8271\n",
      "6m 29s (- 1m 24s) (411 82%) 4.0701\n",
      "6m 31s (- 1m 21s) (414 82%) 3.1261\n",
      "6m 34s (- 1m 18s) (417 83%) 3.3202\n",
      "6m 38s (- 1m 15s) (420 84%) 3.6958\n",
      "6m 41s (- 1m 13s) (423 84%) 3.4528\n",
      "6m 44s (- 1m 10s) (426 85%) 3.5511\n",
      "6m 46s (- 1m 7s) (429 85%) 3.4276\n",
      "6m 48s (- 1m 4s) (432 86%) 3.5452\n",
      "6m 52s (- 1m 1s) (435 87%) 3.8954\n",
      "6m 54s (- 0m 58s) (438 87%) 2.9761\n",
      "6m 58s (- 0m 56s) (441 88%) 4.1165\n",
      "7m 0s (- 0m 53s) (444 88%) 3.2743\n",
      "7m 2s (- 0m 50s) (447 89%) 3.1203\n",
      "7m 6s (- 0m 47s) (450 90%) 4.0144\n",
      "7m 9s (- 0m 44s) (453 90%) 3.0327\n",
      "7m 12s (- 0m 41s) (456 91%) 3.8146\n",
      "7m 15s (- 0m 38s) (459 91%) 4.0811\n",
      "7m 16s (- 0m 35s) (462 92%) 3.0159\n",
      "7m 19s (- 0m 33s) (465 93%) 3.3066\n",
      "7m 22s (- 0m 30s) (468 93%) 3.6856\n",
      "7m 25s (- 0m 27s) (471 94%) 3.4696\n",
      "7m 28s (- 0m 24s) (474 94%) 3.5508\n",
      "7m 30s (- 0m 21s) (477 95%) 3.3876\n",
      "7m 33s (- 0m 18s) (480 96%) 3.5169\n",
      "7m 36s (- 0m 16s) (483 96%) 3.8859\n",
      "7m 38s (- 0m 13s) (486 97%) 2.9738\n",
      "7m 42s (- 0m 10s) (489 97%) 4.1246\n",
      "7m 44s (- 0m 7s) (492 98%) 3.2736\n",
      "7m 45s (- 0m 4s) (495 99%) 3.0194\n",
      "7m 49s (- 0m 1s) (498 99%) 4.0031\n",
      "1\n",
      "0m 5s (- 13m 53s) (3 0%) 3.8912\n",
      "0m 7s (- 10m 12s) (6 1%) 2.9714\n",
      "0m 11s (- 10m 24s) (9 1%) 4.1229\n",
      "0m 13s (- 9m 3s) (12 2%) 3.2798\n",
      "0m 14s (- 7m 57s) (15 3%) 3.0030\n",
      "0m 19s (- 8m 29s) (18 3%) 3.9965\n",
      "0m 21s (- 8m 15s) (21 4%) 3.0319\n",
      "0m 24s (- 8m 10s) (24 4%) 3.8046\n",
      "0m 27s (- 8m 9s) (27 5%) 4.0896\n",
      "0m 29s (- 7m 38s) (30 6%) 3.1044\n",
      "0m 32s (- 7m 35s) (33 6%) 3.2837\n",
      "0m 35s (- 7m 43s) (36 7%) 3.6743\n",
      "0m 38s (- 7m 37s) (39 7%) 3.4560\n",
      "0m 41s (- 7m 34s) (42 8%) 3.5533\n",
      "0m 43s (- 7m 16s) (45 9%) 3.4014\n",
      "0m 45s (- 7m 7s) (48 9%) 3.4921\n",
      "0m 48s (- 7m 11s) (51 10%) 3.8854\n",
      "0m 51s (- 7m 2s) (54 10%) 2.9616\n",
      "0m 55s (- 7m 7s) (57 11%) 4.1058\n",
      "0m 56s (- 6m 56s) (60 12%) 3.2230\n",
      "0m 58s (- 6m 44s) (63 12%) 3.0491\n",
      "1m 2s (- 6m 51s) (66 13%) 3.9942\n",
      "1m 5s (- 6m 47s) (69 13%) 3.0314\n",
      "1m 8s (- 6m 48s) (72 14%) 3.8120\n",
      "1m 11s (- 6m 46s) (75 15%) 4.0315\n",
      "1m 13s (- 6m 36s) (78 15%) 3.0379\n",
      "1m 16s (- 6m 34s) (81 16%) 3.2853\n",
      "1m 20s (- 6m 36s) (84 16%) 3.6683\n",
      "1m 23s (- 6m 35s) (87 17%) 3.4467\n",
      "1m 27s (- 6m 36s) (90 18%) 3.5573\n",
      "1m 28s (- 6m 28s) (93 18%) 3.3868\n",
      "1m 31s (- 6m 24s) (96 19%) 3.4637\n",
      "1m 35s (- 6m 27s) (99 19%) 3.8817\n",
      "1m 38s (- 6m 22s) (102 20%) 2.9642\n",
      "1m 42s (- 6m 24s) (105 21%) 4.1060\n",
      "1m 44s (- 6m 18s) (108 21%) 3.2326\n",
      "1m 45s (- 6m 10s) (111 22%) 3.0553\n",
      "1m 50s (- 6m 13s) (114 22%) 4.0012\n",
      "1m 52s (- 6m 9s) (117 23%) 3.0082\n",
      "1m 56s (- 6m 7s) (120 24%) 3.8117\n",
      "1m 59s (- 6m 4s) (123 24%) 4.0384\n",
      "2m 0s (- 5m 57s) (126 25%) 2.9970\n",
      "2m 3s (- 5m 55s) (129 25%) 3.2847\n",
      "2m 7s (- 5m 56s) (132 26%) 3.6723\n",
      "2m 10s (- 5m 53s) (135 27%) 3.4418\n",
      "2m 13s (- 5m 50s) (138 27%) 3.5548\n",
      "2m 15s (- 5m 44s) (141 28%) 3.3991\n",
      "2m 17s (- 5m 39s) (144 28%) 3.5258\n",
      "2m 21s (- 5m 39s) (147 29%) 3.8769\n",
      "2m 23s (- 5m 34s) (150 30%) 2.9639\n",
      "2m 27s (- 5m 35s) (153 30%) 4.1027\n",
      "2m 29s (- 5m 29s) (156 31%) 3.2498\n",
      "2m 31s (- 5m 24s) (159 31%) 3.0195\n",
      "2m 35s (- 5m 23s) (162 32%) 3.9931\n",
      "2m 37s (- 5m 19s) (165 33%) 3.0125\n",
      "2m 40s (- 5m 16s) (168 33%) 3.8137\n",
      "2m 42s (- 5m 13s) (171 34%) 4.0349\n",
      "2m 44s (- 5m 7s) (174 34%) 3.0979\n",
      "2m 46s (- 5m 4s) (177 35%) 3.2708\n",
      "2m 50s (- 5m 2s) (180 36%) 3.6563\n",
      "2m 52s (- 4m 59s) (183 36%) 3.4469\n",
      "2m 55s (- 4m 56s) (186 37%) 3.5585\n",
      "2m 57s (- 4m 51s) (189 37%) 3.3755\n",
      "2m 59s (- 4m 47s) (192 38%) 3.5100\n",
      "3m 2s (- 4m 46s) (195 39%) 3.8707\n",
      "3m 5s (- 4m 42s) (198 39%) 2.9576\n",
      "3m 10s (- 4m 43s) (201 40%) 4.0932\n",
      "3m 12s (- 4m 39s) (204 40%) 3.2741\n",
      "3m 13s (- 4m 34s) (207 41%) 3.1111\n",
      "3m 17s (- 4m 32s) (210 42%) 3.9778\n",
      "3m 19s (- 4m 29s) (213 42%) 3.0194\n",
      "3m 22s (- 4m 26s) (216 43%) 3.8072\n",
      "3m 25s (- 4m 23s) (219 43%) 4.0487\n",
      "3m 26s (- 4m 18s) (222 44%) 3.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m 29s (- 4m 16s) (225 45%) 3.2690\n",
      "3m 32s (- 4m 14s) (228 45%) 3.6576\n",
      "3m 35s (- 4m 11s) (231 46%) 3.4392\n",
      "3m 38s (- 4m 8s) (234 46%) 3.5285\n",
      "3m 39s (- 4m 4s) (237 47%) 3.4215\n",
      "3m 42s (- 4m 0s) (240 48%) 3.4971\n",
      "3m 45s (- 3m 58s) (243 48%) 3.8609\n",
      "3m 47s (- 3m 55s) (246 49%) 2.9526\n",
      "3m 51s (- 3m 53s) (249 49%) 4.0802\n",
      "3m 53s (- 3m 49s) (252 50%) 3.2518\n",
      "3m 54s (- 3m 45s) (255 51%) 3.0767\n",
      "3m 58s (- 3m 44s) (258 51%) 3.9806\n",
      "4m 1s (- 3m 40s) (261 52%) 3.0043\n",
      "4m 4s (- 3m 38s) (264 52%) 3.7990\n",
      "4m 7s (- 3m 35s) (267 53%) 4.0173\n",
      "4m 8s (- 3m 31s) (270 54%) 3.0241\n",
      "4m 11s (- 3m 29s) (273 54%) 3.2669\n",
      "4m 16s (- 3m 28s) (276 55%) 3.6454\n",
      "4m 19s (- 3m 25s) (279 55%) 3.4311\n",
      "4m 22s (- 3m 23s) (282 56%) 3.5552\n",
      "4m 24s (- 3m 19s) (285 56%) 3.3889\n",
      "4m 27s (- 3m 16s) (288 57%) 3.4222\n",
      "4m 30s (- 3m 14s) (291 58%) 3.8589\n",
      "4m 33s (- 3m 11s) (294 58%) 2.9723\n",
      "4m 37s (- 3m 9s) (297 59%) 4.0745\n",
      "4m 38s (- 3m 5s) (300 60%) 3.2847\n",
      "4m 40s (- 3m 2s) (303 60%) 2.9826\n",
      "4m 44s (- 3m 0s) (306 61%) 3.9724\n",
      "4m 47s (- 2m 57s) (309 61%) 3.0207\n",
      "4m 50s (- 2m 55s) (312 62%) 3.7784\n",
      "4m 54s (- 2m 52s) (315 63%) 4.0104\n",
      "4m 55s (- 2m 49s) (318 63%) 3.0351\n",
      "4m 58s (- 2m 46s) (321 64%) 3.2625\n",
      "5m 2s (- 2m 44s) (324 64%) 3.6552\n",
      "5m 5s (- 2m 41s) (327 65%) 3.4430\n",
      "5m 8s (- 2m 38s) (330 66%) 3.5278\n",
      "5m 10s (- 2m 35s) (333 66%) 3.3829\n",
      "5m 12s (- 2m 32s) (336 67%) 3.4392\n",
      "5m 16s (- 2m 30s) (339 67%) 3.8572\n",
      "5m 18s (- 2m 27s) (342 68%) 2.9633\n",
      "5m 22s (- 2m 25s) (345 69%) 4.0680\n",
      "5m 24s (- 2m 21s) (348 69%) 3.2005\n",
      "5m 25s (- 2m 18s) (351 70%) 3.0637\n",
      "5m 29s (- 2m 15s) (354 70%) 3.9670\n",
      "5m 31s (- 2m 12s) (357 71%) 3.0164\n",
      "5m 34s (- 2m 10s) (360 72%) 3.7751\n",
      "5m 37s (- 2m 7s) (363 72%) 4.0431\n",
      "5m 38s (- 2m 3s) (366 73%) 3.0245\n",
      "5m 42s (- 2m 1s) (369 73%) 3.2552\n",
      "5m 45s (- 1m 58s) (372 74%) 3.6423\n",
      "5m 48s (- 1m 56s) (375 75%) 3.4304\n",
      "5m 51s (- 1m 53s) (378 75%) 3.5677\n",
      "5m 52s (- 1m 50s) (381 76%) 3.3710\n",
      "5m 54s (- 1m 47s) (384 76%) 3.4185\n",
      "5m 58s (- 1m 44s) (387 77%) 3.8556\n",
      "6m 0s (- 1m 41s) (390 78%) 2.9602\n",
      "6m 4s (- 1m 39s) (393 78%) 4.0741\n",
      "6m 6s (- 1m 36s) (396 79%) 3.2572\n",
      "6m 8s (- 1m 33s) (399 79%) 2.9684\n",
      "6m 12s (- 1m 30s) (402 80%) 3.9589\n",
      "6m 14s (- 1m 27s) (405 81%) 3.0030\n",
      "6m 17s (- 1m 25s) (408 81%) 3.7765\n",
      "6m 19s (- 1m 22s) (411 82%) 4.0189\n",
      "6m 21s (- 1m 19s) (414 82%) 2.9855\n",
      "6m 23s (- 1m 16s) (417 83%) 3.2661\n",
      "6m 27s (- 1m 13s) (420 84%) 3.6335\n",
      "6m 31s (- 1m 11s) (423 84%) 3.4410\n",
      "6m 34s (- 1m 8s) (426 85%) 3.5310\n",
      "6m 36s (- 1m 5s) (429 85%) 3.3533\n",
      "6m 39s (- 1m 2s) (432 86%) 3.4748\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-938-20df3cd2e1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/Users/diana/Documents/Project/models_Sonya/decoder_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5000\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_indexes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-874-bf4f814b5fca>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(count, target_indexes, decoder, print_every, plot_every, learning_rate, n_iters, rand)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         loss = train(input_tensor, target_tensor, \n\u001b[0;32m---> 25\u001b[0;31m                      decoder, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-872-4e3e296e2c0e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, decoder, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(i)\n",
    "    torch.save(decoder, \"/Users/diana/Documents/Project/models_Sonya/decoder_\" + str(5000 + i))\n",
    "    trainIters(count, list_indexes, decoder, print_every=3, n_iters = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
